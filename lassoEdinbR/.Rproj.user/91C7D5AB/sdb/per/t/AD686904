{
    "collab_server" : "",
    "contents" : "### code to run in talk ###\n\n### standard regression section\nlibrary(glmnet)\n  \n#download.file(\"http://www.shatterline.com/MachineLearning/data/hiv.rda\",\"hiv.rda\", mode=\"wb\") # Done.\nload(\"hiv.rda\")\t# big matrix of genes, and conference of drug resistance (score)\n\nvisualize.matrix <- function(mat) {\n  print(names(mat))\n  \n  image(1:nrow(mat$x), 1:ncol(mat$x), z=mat$x,\n        col = c(\"darkgreen\", \"white\"),\n        xlab = \"Observations\", ylab = \"Attributes\")\n  \n  title(main = \"Visualizing the Sparse Binary Matrix\",\n        font.main = 4)\n  return (dim(mat$x)) #returns the dimensions of the matrix\n}\n\nvisualize.matrix(hiv.train)\nvisualize.matrix(hiv.test)\n\n# N.B. glmnet needs to work with data as a matrix or sprase.matrix, not a data.frame\n\n\n\n### Initial fitting comparisons\n\ndim(hiv.train$x)\nindx = seq(1,200,by=10)\n\n\nfit <- glmnet(hiv.train$x[,indx], hiv.train$y, alpha = 0)\nplot(fit, \"lambda\", label = T)\n\n\nfit <- glmnet(hiv.train$x[,indx], hiv.train$y, alpha = 1)\nplot(fit, \"lambda\", label = T)\n\n\nfit <- glmnet(hiv.train$x[,indx], hiv.train$y, alpha = 0.03)\nplot(fit, \"lambda\", label = T)\n\n\n\n### Cross validation\n\ncv.f <- cv.glmnet(hiv.train$x[,indx], hiv.train$y, alpha = 0.3)\nplot(cv.f)\n\n# large error is due to restriction\ncv.full <- cv.glmnet(hiv.train$x, hiv.train$y, alpha = 0.3)\nplot(cv.full)\n\n# these values are fine for this purpose:\ncv.f$lambda.min\ncv.f$lambda.1se\n\n# if you're interested in parameter estimation, effect sizes\ncoef(fit,s=cv.f$lambda.1se)\n\n\n\n### Prediction\nfit.full = glmnet(hiv.train$x, hiv.train$y, alpha = 0.3) # return to the full set\npred.y <- predict(fit.full, hiv.test$x) # predict from the test data\n\nmean.sq.test.error <- apply((pred.y - hiv.test$y)^2,2,mean)\n\npoints(log(fit.full$lambda), mean.sq.test.error, col=\"blue\",pch=\"*\")\nlegend(\"topleft\",legend=c(\"10-fold Cross Validation\",\"Test HIV Data\"),pch=\"*\",col=c(\"red\",\"blue\"))\n# pretty good...\n\n\n\n\n\n\n\n\n\n\n### Stability Selection\n\nlibrary(stabs)\n\n\nstab.lasso <- stabsel(x = hiv.train$x[,indx], y = hiv.train$y,\n                      fitfun = glmnet.lasso, cutoff = 0.75, PFER = 1,\n                      B = 1000)\n\n# cutoff: Semi-arbitrary, hardline used for counting variables as in or out\n#         guidelines: [0.6 to 0.9] (maybe even [0.5 to 1])\n#\n# PFER: Per-family error rate; the maximum number of acceptable false positives\n\nplot(stab.lasso, main = \"Lasso\")\n\n\n\ndf = data.frame(hiv.train$y,hiv.train$x[,indx])\n#form = as.formula(paste(\"roll_pct ~ \", paste(as.vector(colnames(hiv.train$x[,indx])), sep =\"+\"),sep = \"\"))\n\nlm1 <- lm(hiv.train.y ~ . , data = df)\nlm1.step <- step(lm1, direction = 'backward', trace = 0)\nsummary(lm1.step)\n\nlm2 <- lm(hiv.train.y ~ 1, data = df)\nlm2.step <- step(lm2, scope = formula(df), direction ='forward', trace=0)\nsummary(lm2.step)\n\n\n\n",
    "created" : 1473948379413.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "621271967",
    "id" : "AD686904",
    "lastKnownWriteTime" : 1494844781,
    "last_content_update" : 1494844781,
    "path" : "C:/Users/s1229179/GitHub/R/lassoEdinbR/demo.R",
    "project_path" : "demo.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}