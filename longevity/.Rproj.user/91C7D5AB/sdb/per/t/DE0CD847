{
    "collab_server" : "",
    "contents" : "### Importation and Processing\n\n# TODO:\n# go thru zoos and find the last census date for AZA LTFs\n#   a question about (Little?) Debbie - for biomarker sheet\n#   Brodie, Chip, Drew, Pericles, Rita, Steward, Virginia are \n#   also on BM list and are ALIVE\n\n\nall <- read.csv(\"long_all.csv\")\n# cutting off the bottom\nall <- all[-c(558:dim(all)[1]),]\n\n# removing row at 378, where the questionnaire changes\nall <- all[-378,]\n\nall[,c(7:60)] <- lapply((all[,c(7:60)]), as.character)\nall[,c(7:60)] <- lapply((all[,c(7:60)]), as.numeric)\n\nall$status[(all$status == '') & (all$sample == 'AZA')] <- 'Alive'\nall$status[(all$status == 'LTF') & (all$sample == 'AZA')] <- 'Alive'\n\nall$status[(all$status == 'LTF') & (all$sample == 'Taronga')] <- 'Alive'\n\nall$status[(all$status == 'LTF') & (all$sample == 'Yerkes')] <- 'Alive'\n\nall$status[(all$status == 'dead') & (all$sample == 'Japan')] <- 'Death'\nall$status[(all$status == 'alive') & (all$sample == 'Japan')] <- 'Alive'\n\n# just for Bram - whach out for the number\nall$status[535] <- 'Alive'\ntable(all$status)\n# for frailty purposes, we want to make Taronga part of AZA\nall$sample[all$sample=='Taronga'] = 'AZA'\n\n#levels(all$sample)\n\n# remove the 'rm's until a better situation is realized\n### TODO: come up with a better alternative\nall <- all[!all$status == 'rm',]\n\n\n# Dating shenanigans\n\nall$DoB <- as.Date(all$DoB,format='%m/%d/%Y')\nall$lastDate <- as.Date(all$lastDate, format='%d/%m/%Y')\n\n\n### Ageing\n# ... should also be age at Personality rating\n\n# age at last known date\n#head(all$lastDate - all$DoB)\nall$age = as.numeric(difftime(all$lastDate, all$DoB, units = \"weeks\"))/52.25 \n# The above is super useful. Remember that (it is here).\n\n# making age at DOPR for Yerkes & Edinburgh\n# see other files - there may be an issue with death dates overlapping\nall$DOPR = as.Date(all$DOPR,format='%m/%d/%Y')\nall$DOPR2 = as.Date(all$DOPR2,format='%m/%d/%Y')\nall$DOPRmin = pmin(all$DOPR, all$DOPR2, na.rm = TRUE)\n\n# some death dates cut off\n# all$DOPRmin = pmin(all$DOPRmin, all$lastDate) # this was a PROBLEM\n\n### TODO: set a cut-off for the rating/death date\n\n\n\nind = all$sample == 'Yerkes' | all$sample == 'Edinburgh'\n\nall$age_pr[ind] = as.numeric(difftime(\n  all$DOPRmin[ind], all$DoB[ind], units = \"weeks\"))/52.25 \n\nlibrary(lubridate)\nall$DOPRmin[(all$sample == 'AZA') | (all$sample == 'Taronga')] <- \n  all$DoB[(all$sample == 'AZA') | (all$sample == 'Taronga')] + all$age_pr[(all$sample == 'AZA') | (all$sample == 'Taronga')]\n\nyr = year(all$DoB[(all$sample == 'AZA') | (all$sample == 'Taronga')]) +\n  all$age_pr[(all$sample == 'AZA') | (all$sample == 'Taronga')]\n\nall$DOPRmin[(all$sample == 'AZA') | (all$sample == 'Taronga')] <- (as.Date(date_decimal(yr)))\n\n# Some animals died before being rated.\n# Test: moving their rating date to a month or year back from DoD\n\nall$age_pr_adj = all$age_pr\nall$age_pr_adj[all$age <= all$age_pr & (all$sample %in% c('Taronga', 'Yerkes', 'AZA'))] <-\n  (all$age_pr_adj[all$age <= all$age_pr & (all$sample %in% c('Taronga', 'Yerkes', 'AZA'))] - 5)\n\n\n### Origin\n# are these appropriate?\n# all$origin[all$sample == 'AZA' & all$origin == 'UNKNOWN'] <- #'CAPTIVE' \n# \n# all$origin[(all$sample == 'Yerkes' | all$sample == 'Taronga') & all$origin == ''] <- 'CAPTIVE'\n# all$origin[(all$sample == 'Yerkes' | all$sample == 'Taronga') & all$origin == 'W'] <- 'WILD'\nall$origin[all$origin == ''] <- 'CAPTIVE'\nall$origin[all$origin == 'W'] <- 'WILD'\nall$origin[all$origin == 'UNKNOWN'] <- 'CAPTIVE'\n\ntable(all$origin)\n# library(dplyr) # needed?\nall$origin = droplevels(all$origin)\n\n### Lab vs. Zoo\n\nall$LvZ[all$sample == 'AZA'] <- 'zoo'\nall$LvZ[all$sample == 'Yerkes'] <- 'lab'\nall$LvZ[all$sample == 'Taronga'] <- 'zoo'\n\n###\n# there're rearing styles in the AZA file...\n# and the Yerkes hematology file...\n\n\n\n### creating personality scores\n\n\n# right now this is being applied to all\n# will need to create HPQ composites later\n# and compare the possibilities\n\n\nall$Dom = NA\nall$Ext = NA\nall$Con = NA\nall$Agr = NA\nall$Neu = NA\nall$Opn = NA\n\n\nind = (all$sample == 'AZA' | all$sample == 'Yerkes' | all$sample == 'Taronga')\n\nall[ind,]$Dom <-\n  (all[ind,]$dom-all[ind,]$subm-all[ind,]$depd+all[ind,]$indp-all[ind,]$fear+all[ind,]$decs\n   -all[ind,]$tim-all[ind,]$caut+all[ind,]$intll+all[ind,]$pers+all[ind,]$buly+all[ind,]$stngy+40)/12\n\nall[ind,]$Ext <-\n  (-all[ind,]$sol-all[ind,]$lazy-all[ind,]$depr\n   +all[ind,]$actv+all[ind,]$play+all[ind,]$soc+all[ind,]$frdy+all[ind,]$affc+all[ind,]$imit+24)/9\n\nall[ind,]$Con <-\n  (-all[ind,]$impl-all[ind,]$defn-all[ind,]$reckl-all[ind,]$errc-all[ind,]$irri\n   +all[ind,]$pred-all[ind,]$aggr-all[ind,]$jeals-all[ind,]$dsor+64)/9\n\nall[ind,]$Agr <-\n  (all[ind,]$symp+all[ind,]$help+all[ind,]$sens+all[ind,]$prot+all[ind,]$gntl)/5\n\nall[ind,]$Neu <-\n  (-all[ind,]$stbl+all[ind,]$exct-all[ind,]$unem+16)/3\n\nall[ind,]$Opn <-\n  (all[ind,]$inqs+all[ind,]$invt) /2\n  \n\n\nind = (all$sample == 'Japan' | all$sample == 'Edinburgh') \n\nall[ind,]$Dom <-\n  (all[ind,]$dom\n   -all[ind,]$subm\n   -all[ind,]$depd\n   +all[ind,]$indp\n   -all[ind,]$fear\n   +all[ind,]$decs\n   -all[ind,]$tim\n   -all[ind,]$caut\n   +all[ind,]$intll\n   +all[ind,]$pers\n   +all[ind,]$buly\n   +all[ind,]$stngy\n   -all[ind,]$Vuln - all[ind,]$Anx + all[ind,]$manp + 56)/15\n\nall[ind,]$Ext <-\n  (-all[ind,]$sol-all[ind,]$lazy-all[ind,]$depr\n   +all[ind,]$actv+all[ind,]$play+all[ind,]$soc+all[ind,]$frdy+all[ind,]$affc+all[ind,]$imit\n   -all[ind,]$Indv + 32)/10\n\nall[ind,]$Con <-\n  (-all[ind,]$impl-all[ind,]$defn-all[ind,]$reckl-all[ind,]$errc-all[ind,]$irri\n   +all[ind,]$pred-all[ind,]$aggr-all[ind,]$jeals-all[ind,]$dsor\n   - all[ind,]$Thot - all[ind,]$Dist - all[ind,]$Unper - all[ind,]$Quit - all[ind,]$clmy + 104)/14\n\nall[ind,]$Agr <-\n  (all[ind,]$symp+all[ind,]$help+all[ind,]$sens+all[ind,]$prot+all[ind,]$gntl\n   + all[ind,]$Conv)/6\n\nall[ind,]$Neu <-\n  (-all[ind,]$stbl+all[ind,]$exct-all[ind,]$unem\n   - all[ind,]$Cool + all[ind,]$aut + 24)/5\n\nall[ind,]$Opn <-\n  (all[ind,]$inqs+all[ind,]$invt\n   + all[ind,]$Cur + all[ind,]$Innov) / 4\n\n\n# Scale each dimension across all chimps\nall$Dom_CZ <- scale(all$Dom)\nall$Ext_CZ <- scale(all$Ext)\nall$Con_CZ <- scale(all$Con)\nall$Agr_CZ <- scale(all$Agr)\nall$Neu_CZ <- scale(all$Neu)\nall$Opn_CZ <- scale(all$Opn)\n\n# removing individuals who died before rating\nrmovals <- which((all$age - all$age_pr) < 0.0)   # 29, 505, ++...\n# is 0 enough, or do we need a buffer?\nall <- (all[-c(rmovals),])\n\n# NOTICE:\n# There is something really weird going on here \n# where ahaz doesn't handle the data the outcomes\n# the same way even though the numbers are the same \n# as the T/Fs\n# Does it matter? Probably.\n# What can be done about it?\n\n\n# all$status <- droplevels(all$status)\n# \n# levels(all$status)[levels(all$status)==\"Death\"] <- TRUE\n# levels(all$status)[levels(all$status)==\"Alive\"] <- FALSE\n# \n# all$status = as.logical(all$status)\n\n### Comment / uncomment\n# # changing to the midpoint for the interval dated Yerkes chimps\n# all[all$chimp %in% y16changes,]$status = 'Death'\n# all[all$chimp %in% y16changes,]$lastDate = as.factor(as.Date('24/08/2013', format=\"%d/%m/%Y\"))\n# # It kind of shits up the model though. What if we make is the endpoint?\n# all[all$chimp %in% y16changes,]$lastDate = as.Date(\"01/02/16\", format=\"%d/%m/%y\")\n# # Doesn't seem to make it much better.\n# # TODO: compare to imputations\n\n\n### Regression prepping\n\n# formerly at beginning of analysis scripts\n\nlibrary(survival)\n\n# Dataset <- all[(all$sample == 'AZA') \n#                | (all$sample == 'Yerkes') | (all$sample == 'Taronga'),]\n### !!!\n### something is going wrong with the regressions since adding all the new data\n#Dataset <- all[all$sample == 'Yerkes',]\n#Dataset = all[sample(nrow(all), 200), ]\n#Dataset <- all[(all$age-all$age_pr) > 2,]\nDataset <- all\n\n\nDataset$origin <- droplevels(Dataset$origin)\n\n# RIGHT censoring - matching 'time' and 'event'\n\n## see notice above ###\n\nDataset$stat.log <- droplevels(Dataset$status)\n\nlevels(Dataset$status)[levels(Dataset$status)==\"Death\"] <- 1\nlevels(Dataset$status)[levels(Dataset$status)==\"Alive\"] <- 0\n\n\nlevels(Dataset$stat.log)[levels(Dataset$stat.log)==\"Death\"] <- TRUE\nlevels(Dataset$stat.log)[levels(Dataset$stat.log)==\"Alive\"] <- FALSE\n\nDataset$stat.log = as.logical(Dataset$stat.log)\n\n# Stratification\n\nDataset$strt = NA\nDataset$strt[Dataset$age_pr < 8] <- 1\nDataset$strt[(Dataset$age_pr > 8) & (Dataset$age_pr < 15)] <- 2\nDataset$strt[(Dataset$age_pr > 15) & (Dataset$age_pr < 25)] <- 3\nDataset$strt[(Dataset$age_pr > 25) & (Dataset$age_pr < 35)] <- 4\nDataset$strt[(Dataset$age_pr > 35)] <- 5\n\n\n\n#######################\n\ny <- Surv(as.numeric(Dataset$age),Dataset$stat.log)\n\n\n# adding LEFT truncation\n\n# Obsolete:\n# # currently optional - my attempt to control for age effects within E\n# Dataset$adjE <- scale(Dataset$Ext_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n# # and now O\n# Dataset$adjO <- scale(Dataset$Opn_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n# # hell, what if we do it for all of them?\n# Dataset$adjD <- scale(Dataset$Dom_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n# Dataset$adjC <- scale(Dataset$Con_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n# Dataset$adjA <- scale(Dataset$Agr_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n# Dataset$adjN <- scale(Dataset$Neu_CZ-scale(1/(1 + Dataset$age_pr_adj)))\n\n\n#y.Ltrunc <- Surv(as.numeric(Dataset$DOPRmin), as.numeric(Dataset$lastDate),Dataset$status ,\n#                 type='counting')\ny.Ltrunc <- Surv(Dataset$age_pr, Dataset$age,Dataset$stat.log,  # previously age_pr_adj\n                 type='counting')\n\n# attr(y.Ltrunc, 'type') <- 'counting' # this is needed to be able to handle Cox\n\nrmNAs = !is.na(y.Ltrunc)\n\nyLt = y.Ltrunc[rmNAs]\n#attr(y.Ltrunc, 'type')\n#attr(yLt, 'type')\ndatX = Dataset[rmNAs,]\n\n\n### P dimensions confounded with age\n\nlibrary(bbmle)\n\n## Extraversion\n\nfit.e0 <- lm(Ext_CZ ~ 1, data=datX)\n# residual entry for quadratic, cubic regs:\nfit.e1 <- lm(Ext_CZ ~ scale(age_pr_adj), data=datX)\nfit.e2 <- lm(Ext_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2), data=datX)\ndatX$E.resid2 <- fit.e2$residuals\nfit.e3 <- lm(Ext_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2) + I(scale(age_pr_adj)^3), data=datX)\ndatX$E.resid3 <- fit.e3$residuals\n\nanova(fit.e1,fit.e2,fit.e3)\n\n# DoB based?\nfit.e1.DoB <- lm(Ext_CZ ~ scale(DoB), data=datX)\nfit.e2.DoB <- lm(Ext_CZ ~ scale(DoB) + I(scale(DoB)^2), data=datX) # this seems to be the best (see anova)\nfit.e3.DoB <- lm(Ext_CZ ~ scale(DoB) + I(scale(DoB)^2) + I(scale(DoB)^3), data=datX) # No, this is best (see AIC)\n\nanova(fit.e0,fit.e1.DoB,fit.e2.DoB,fit.e3.DoB)\n#anova(fit.e1,fit.e2,fit.e3,fit.e1.DoB,fit.e2.DoB,fit.e3.DoB)\n\nAICctab(fit.e0,fit.e1.DoB,fit.e2.DoB,fit.e3.DoB #,fit.e1,fit.e2,fit.e3,\n       ,logLik=T,weights=T,base=T,delta=T)\n\ndatX$E.r3.DoB <- fit.e3.DoB$residuals\ndatX$E.r3 <- fit.e3$residuals\n# added for sake of LASSO\ndatX$E.r2.DoB <- fit.e2.DoB$residuals # yup ~ stabsel\n\n\n# what do these residuals look like?\n\nplot(datX$Ext_CZ, datX$E.r2.DoB)\nplot(datX$age_pr, datX$E.r2.DoB)\n\nplot(datX$Ext_CZ, datX$E.resid3)\nplot(datX$age_pr_adj, datX$E.resid3)\n\n\n## Openness\nfit.o0 <- lm(Opn_CZ ~ 1, data=datX)\nfit.o1 <- lm(Opn_CZ ~ scale(age_pr_adj), data=datX)\nfit.o2 <- lm(Opn_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2), data=datX)\nfit.o3 <- lm(Opn_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2) + I(scale(age_pr_adj)^3), data=datX)\nfit.o1.DoB <- lm(Opn_CZ ~ scale(DoB), data=datX) # this, according to LASSO\nfit.o2.DoB <- lm(Opn_CZ ~ scale(DoB) + I(scale(DoB)^2), data=datX) # or this, according to stabsel\nfit.o3.DoB <- lm(Opn_CZ ~ scale(DoB) + I(scale(DoB)^2) + I(scale(DoB)^3), data=datX)\n\nAICctab(fit.o0,fit.o1.DoB,fit.o2.DoB,fit.o3.DoB #, fit.o1,fit.o2,fit.o3\n       , logLik=T,weights=T,base=T,delta=T)\n\nanova(fit.o1,fit.o2,fit.o3,fit.o1.DoB,fit.o2.DoB,fit.o3.DoB)\n\n\ndatX$O.r2.DoB <- fit.o2.DoB$residuals # these ~ stabsel\n  datX$O.r2 <- fit.o2$residuals\n  \ndatX$O.r1.DoB <- fit.o1.DoB$residuals\n\nplot(datX$age_pr, datX$O.r1.DoB)\nplot(datX$age_pr, datX$O.r2.DoB)\n\n\n## Dominance\n\nfit.d0 <- lm(Dom_CZ ~ 1, data=datX)\nfit.d1 <- lm(Dom_CZ ~ scale(age_pr_adj), data=datX)\nfit.d2 <- lm(Dom_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2), data=datX)\nfit.d3 <- lm(Dom_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2) + I(scale(age_pr_adj)^3), data=datX)\nfit.d1.DoB <- lm(Dom_CZ ~ scale(DoB), data=datX)\nfit.d2.DoB <- lm(Dom_CZ ~ scale(DoB) + I(scale(DoB)^2), data=datX) # this ~ stabsel\nfit.d3.DoB <- lm(Dom_CZ ~ scale(DoB) + I(scale(DoB)^2) + I(scale(DoB)^3), data=datX) \n\nAICctab(fit.d0, fit.d1.DoB,fit.d2.DoB,fit.d3.DoB #,fit.d1,fit.d2,fit.d3\n       ,logLik=T,weights=T,base=T,delta=T)\n\nanova(fit.d0, fit.d1,fit.d2,fit.d3,fit.d1.DoB,fit.d2.DoB,fit.d3.DoB)\n\n\ndatX$D.r2.DoB <- fit.d2.DoB$residuals\ndatX$D.r3.DoB <- fit.d3.DoB$residuals\ndatX$D.r3 <- fit.d3$residuals\n\n\n## Neuroticism\n\nfit.n0 <- lm(Neu_CZ ~ 1, data=datX)\nfit.n1 <- lm(Neu_CZ ~ scale(age_pr_adj), data=datX)\nfit.n2 <- lm(Neu_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2), data=datX)\nfit.n3 <- lm(Neu_CZ ~ scale(age_pr_adj) + I(scale(age_pr_adj)^2) + I(scale(age_pr_adj)^3), data=datX)\nfit.n1.DoB <- lm(Neu_CZ ~ scale(DoB), data=datX) # This one ~ stabsel\nfit.n2.DoB <- lm(Neu_CZ ~ scale(DoB) + I(scale(DoB)^2), data=datX)\nfit.n3.DoB <- lm(Neu_CZ ~ scale(DoB) + I(scale(DoB)^2) + I(scale(DoB)^3), data=datX)\n\nAICctab(fit.n0, fit.n1.DoB,fit.n2.DoB,fit.n3.DoB #,fit.n1,fit.n2,fit.n3,\n       ,logLik=T,weights=T,base=T,delta=T)\n\nanova(fit.n0, fit.n1,fit.n2,fit.n3,fit.n1.DoB,fit.n2.DoB,fit.n3.DoB)\n\n\ndatX$N.r1.DoB <- fit.n1.DoB$residuals  # these\ndatX$N.r1 <- fit.n1$residuals\n\n\n\n## Conscientiousness\n\nfit.c2.DoB <- lm(Con_CZ ~ I(scale(DoB)^2), data=datX)\ndatX$C.r.DoB = fit.c2.DoB$residuals\n\n## Agreeableness\n\nfit.a2.DoB <- lm(Agr_CZ ~ I(scale(DoB)^2), data=datX)\ndatX$A.r.DoB = fit.a2.DoB$residuals\n\nplot(datX$age_pr, datX$Agr_CZ)\nplot(datX$age_pr, datX$A.r.DoB)\n\n\n\n\n# stop indendation\n\n\n\n\n\n\n\n\n# let's try a LASSO...\n\nlibrary(glmnet)\nlibrary(c060)\n# #detach('package:c060')\nlibrary(stabs)\n# library(caret)\n# # see also chimpAnalyses.R\n# \nnetform = data.frame(cbind(scale(datX$DoB),\n                scale(datX$DoB)^2,\n                scale(datX$DoB)^3))\ncolnames(netform) = c(\"DoB1\",\"DoB2\",\"DoB3\")\n\nrmatx = model.matrix( ~ DoB1 + DoB2 + DoB3 - 1, netform)\n\n#stab.E = stabpath(datX$Ext_CZ, rmatx, weakness = 0.7 ) # 0.2 to 0.8\nstab.E = stabsel(rmatx, datX$Ext_CZ, fitfun=glmnet.lasso,\n                 cutoff = 0.9,\n                 #q = 3 ,\n                 PFER = 1\n                 )\nparameters(stab.E)\n\nstab.D = stabsel(rmatx, datX$Dom_CZ, fitfun=glmnet.lasso, #q = 3\n                 cutoff = 0.8, PFER = 1)\nstab.A = stabsel(rmatx, datX$Agr_CZ, fitfun=glmnet.lasso, #q = 3\n                 cutoff = 0.8, PFER = 1)\nstab.C = stabsel(rmatx, datX$Con_CZ, fitfun=glmnet.lasso, #q = 3\n                 cutoff = 0.8, PFER = 1)\nstab.N = stabsel(rmatx, datX$Neu_CZ, fitfun=glmnet.lasso, #q = 3\n                 cutoff = 0.8, PFER = 1)\nstab.O = stabsel(rmatx, datX$Opn_CZ, fitfun=glmnet.lasso, #q = 3\n                 cutoff = 0.8, PFER = 1)\n\n\n\n\nstab.D = stabpath(datX$Dom_CZ, rmatx, weakness = 0.7 )\nstab.C = stabpath(datX$Con_CZ, rmatx, weakness = 0.7 )\nstab.N = stabpath(datX$Neu_CZ, rmatx, weakness = 0.7 )\nstab.A = stabpath(datX$Agr_CZ, rmatx, weakness = 0.7 )\nstab.O = stabpath(datX$Opn_CZ, rmatx, weakness = 0.7 )\n\nplot(stab.E, type = 'paths')\nplot(stab.D, type = 'paths')\nplot(stab.C, type = 'paths')\nplot(stab.N, type = 'paths')\nplot(stab.A, type = 'paths')\nplot(stab.O, type = 'paths')\n# \n# data(\"bodyfat\", package = \"TH.data\")\n# stab.lasso <- stabsel(x = bodyfat[, -2], y = bodyfat[,2],\n#                        fitfun = glmnet.lasso, cutoff = 0.75,\n#                        PFER = 1)\n# par(mfrow = c(2, 1))\n# plot(stab.lasso, ymargin = 6)\n# opar <- par(mai = par(\"mai\") * c(1, 1, 1, 2.7))\n# plot(stab.lasso, type = \"paths\")\n# \n# \n# \n# eGrid <- expand.grid(.alpha = seq(0,1,0.01), \n#                      .lambda = lseq(0.0005, 300, 1000))\n# \n# Control <- trainControl(method = \"cv\",repeats = 5,verboseIter = F)\n# \n# netFitE <- train(x = rmatx, y = as.numeric(datX$Ext_CZ)\n#                 , method = \"glmnet\",\n#                 metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                 , tuneGrid = eGrid,\n#                 trControl = Control )\n# \n# netFitO <- train(x = rmatx, y = as.numeric(datX$Opn_CZ)\n#                  , method = \"glmnet\",\n#                  metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                  , tuneGrid = eGrid,\n#                  trControl = Control )\n# \n# netFitC <- train(x = rmatx, y = as.numeric(datX$Con_CZ)\n#                  , method = \"glmnet\",\n#                  metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                  , tuneGrid = eGrid,\n#                  trControl = Control )\n# \n# netFitD <- train(x = rmatx, y = as.numeric(datX$Dom_CZ)\n#                  , method = \"glmnet\",\n#                  metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                  , tuneGrid = eGrid,\n#                  trControl = Control )\n# \n# netFitA <- train(x = rmatx, y = as.numeric(datX$Agr_CZ)\n#                  , method = \"glmnet\",\n#                  metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                  , tuneGrid = eGrid,\n#                  trControl = Control )\n# \n# netFitN <- train(x = rmatx, y = as.numeric(datX$Neu_CZ)\n#                  , method = \"glmnet\",\n#                  metric = 'RMSE' #c(\"Accuracy\",\"Kappa\"),\n#                  , tuneGrid = eGrid,\n#                  trControl = Control )\n# \n# # > netFitD$bestTune\n# # alpha    lambda\n# # 111     0 0.1040099\n# # > netFitO$bestTune\n# # alpha     lambda\n# # 84     0 0.02805985\n# # > netFitA$bestTune\n# # alpha    lambda\n# # 140     0 0.4248263\n# # > netFitN$bestTune\n# # alpha    lambda\n# # 1045  0.03 0.5414767\n# # > netFitC$bestTune\n# # alpha     lambda\n# # 71     0 0.01493233\n# # > netFitE$bestTune\n# # alpha     lambda\n# # 30079     1 0.02201491\n# \n# \n# lasso.rE = glmnet(rmatx, datX$Ext_CZ, #grouped=FALSE\n#                  )\n# lasso.rE.cv = cv.glmnet(rmatx, datX$Ext_CZ)\n# \n# plot(lasso.rE.cv)\n# \n# plot(lasso.rE, label=T)\n# plot(lasso.rE, xvar=\"lambda\", label=T)\n# plot(lasso.rE, xvar=\"dev\", label=T)\n# \n# coef(lasso.rE, s = 0.02201491\n#      #s=lasso.rE.cv$lambda.1se\n# )\n# # well, this says to leave out the cubic\n# \n# datX$E.cv.r = datX$Ext_CZ - predict(lasso.rE, rmatx, s=0.022\n#                  #s = lasso.rE.cv$lambda.1se\n#                  )\n# # plot(datX$age_pr, #E.cv.r)\n# #        datX$E.r2.DoB)\n# \n# \n# lasso.rD = glmnet(rmatx, datX$Dom_CZ, alpha = 0)\n# lasso.rD.cv = cv.glmnet(rmatx, datX$Dom_CZ, alpha = 0)\n# plot(lasso.rD, label=T)\n# coef(lasso.rD, s= 0.104)\n#        # lasso.rD.cv$lambda.min)\n# \n# datX$D.cv.r = datX$Dom_CZ - predict(lasso.rD, rmatx, s=0.104)\n# \n# \n# #stab.D = stabpath(datX$Dom_CZ, rmatx)\n# # stab.D = stabsel(rmatx, datX$Dom_CZ, fitfun=glmnet.lasso,\n# #                  cutoff = 0.8, \n# #                  #q = 3 , \n# #                  PFER = 1.2\n# # )\n# # plot(stab.D)\n# \n# lasso.rC = glmnet(rmatx, datX$Con_CZ, alpha = 0.0)\n# lasso.rC.cv = cv.glmnet(rmatx, datX$Con_CZ, alpha = 0.0)\n# plot(lasso.rC.cv, label=T)\n# coef(lasso.rC, s = 0.015\n#      #s=lasso.rC.cv$lambda.1se\n#      )\n# \n# datX$C.cv.r = datX$Con_CZ - predict(lasso.rC, rmatx, s = 0.015)\n#                                       \n# \n# lasso.rA = glmnet(rmatx, datX$Agr_CZ, alpha = 0)\n# lasso.rA.cv = cv.glmnet(rmatx, datX$Agr_CZ, alpha = 0)\n# plot(lasso.rA.cv, label=T)\n# coef(lasso.rA, #s= 0.5\n#        s = lasso.rA.cv$lambda.1se\n#        )\n# \n# datX$A.cv.r = datX$Agr_CZ - predict(lasso.rA, rmatx, s = 0.425)\n# \n#                                       \n# lasso.rO = glmnet(rmatx, datX$Opn_CZ , alpha = 0.00)\n# lasso.rO.cv = cv.glmnet(rmatx, datX$Opn_CZ , alpha = 0.00)\n# plot(lasso.rO, label=T, xvar = 'dev')\n# coef(lasso.rO, #s=0.01)\n#      s=lasso.rO.cv$lambda.min)\n# \n# datX$O.cv.r = datX$Opn_CZ - predict(lasso.rO, rmatx, s = 0.028)\n# \n# \n# lasso.rN = glmnet(rmatx, datX$Neu_CZ , alpha = 0.03)\n# lasso.rN.cv = cv.glmnet(rmatx, datX$Neu_CZ , alpha = 0.03)\n# plot(lasso.rN, label=T)\n# plot(lasso.rN.cv)\n# coef(lasso.rN, s= 0.5414767\n#      #s=lasso.rN.cv$lambda.1se\n#      )\n# \n# datX$N.cv.r = datX$Neu_CZ - predict(lasso.rN, rmatx, s = 0.541)\n# \n\nlasso.rE = glmnet(rmatx, datX$Ext_CZ)\nlasso.rE.cv = cv.glmnet(rmatx, datX$Ext_CZ)\ncoef(lasso.rE, s=lasso.rE.cv$lambda.1se)\nlasso.rD = glmnet(rmatx, datX$Dom_CZ)\nlasso.rD.cv = cv.glmnet(rmatx, datX$Dom_CZ)\ncoef(lasso.rD, s=lasso.rD.cv$lambda.1se)\nlasso.rC = glmnet(rmatx, datX$Con_CZ)\nlasso.rC.cv = cv.glmnet(rmatx, datX$Con_CZ)\ncoef(lasso.rC, s=lasso.rC.cv$lambda.1se)\nlasso.rA = glmnet(rmatx, datX$Agr_CZ)\nlasso.rA.cv = cv.glmnet(rmatx, datX$Agr_CZ)\ncoef(lasso.rA, s=lasso.rA.cv$lambda.1se)\nlasso.rO = glmnet(rmatx, datX$Opn_CZ)\nlasso.rO.cv = cv.glmnet(rmatx, datX$Opn_CZ)\ncoef(lasso.rO, s=lasso.rO.cv$lambda.1se)\nlasso.rN = glmnet(rmatx, datX$Neu_CZ)\nlasso.rN.cv = cv.glmnet(rmatx, datX$Neu_CZ)\ncoef(lasso.rN, s=lasso.rN.cv$lambda.1se)\n# lasso.rE.cv$lambda.1se\n# coef(lasso.rE, s=lasso.rE.cv$lambda.1se)\ndatX$N.cv.r = datX$Neu_CZ - predict(lasso.rN, rmatx, s = lasso.rN.cv$lambda.1se )\ndatX$D.cv.r = datX$Dom_CZ - predict(lasso.rD, rmatx, s = lasso.rD.cv$lambda.1se )\ndatX$E.cv.r = datX$Ext_CZ - predict(lasso.rE, rmatx, s = lasso.rE.cv$lambda.1se )\ndatX$A.cv.r = datX$Agr_CZ - predict(lasso.rA, rmatx, s = lasso.rA.cv$lambda.1se )\ndatX$C.cv.r = datX$Con_CZ - predict(lasso.rC, rmatx, s = lasso.rC.cv$lambda.1se )\ndatX$O.cv.r = datX$Opn_CZ - predict(lasso.rO, rmatx, s = lasso.rO.cv$lambda.1se )\n\n# datX$N.cv.r = datX$Neu_CZ - predict(lasso.rN, rmatx, s = lasso.rN.cv$lambda.min )\n# datX$D.cv.r = datX$Dom_CZ - predict(lasso.rD, rmatx, s = lasso.rD.cv$lambda.min )\n# datX$E.cv.r = datX$Ext_CZ - predict(lasso.rE, rmatx, s = lasso.rE.cv$lambda.min )\n# datX$A.cv.r = datX$Agr_CZ - predict(lasso.rA, rmatx, s = lasso.rA.cv$lambda.min )\n# datX$C.cv.r = datX$Con_CZ - predict(lasso.rC, rmatx, s = lasso.rC.cv$lambda.min )\n# datX$O.cv.r = datX$Opn_CZ - predict(lasso.rO, rmatx, s = lasso.rO.cv$lambda.min )\n## over does it\n\n\n# tst = c(2:10 %o% 10^(3:7))\n# tst = lseq(0.0005, 1000, 300)\n# plot(tst)\n\n\n## these suggest the quadratic for E, and the linear for E and O\n\n\ntestSurvDist <- function(thedistributions, model){\n  distlist = 0\n  LLlist1 = 0\n  LLlist2 = 0\n  estimates = 0\n  fAIC = NULL\n  for (i in 1:length(thedistributions)) {\n    thisdist = thedistributions[i]\n    fit = survreg(model, dist = thisdist)\n    distlist[i] = thisdist\n    LLlist1[i] = -2*(fit$loglik[1])\n    LLlist2[i] = -2*(fit$loglik[2])\n    fAIC[i] = extractAIC(fit)[2]\n    estimates[i] = exp(as.numeric(fit$coefficients[2]))  }\n  Result = data.frame(distlist, LLlist1, LLlist2, estimates, LLlist1 - LLlist2, fAIC)\n  names(Result) = c(\"Distribution\", \"-2*LL(Baseline)\", \"-2*LL(Full)\",\"Estimate\", 'LL diff','AIC')\n  Result = Result[order(Result[,3]),]\n  Result\n}\n\n\nlseq <- function(from=1, to=100000, length.out=6) {\n  # logarithmic spaced sequence\n  # blatantly stolen from library(\"emdbook\"), because need only this\n  exp(seq(log(from), log(to), length.out = length.out))\n}\n",
    "created" : 1448268337902.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1569698298",
    "id" : "DE0CD847",
    "lastKnownWriteTime" : 1478258933,
    "last_content_update" : 1478258933820,
    "path" : "C:/Users/s1229179/GitHub/R/longevity/importProcess.R",
    "project_path" : "importProcess.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}